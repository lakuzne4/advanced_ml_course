{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:07:26.591492Z",
     "start_time": "2021-05-11T15:07:25.768776Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "from collections import namedtuple, Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import product\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотреть данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отобрать нужные записи из results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:08:45.694276Z",
     "start_time": "2021-05-11T15:07:26.591492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Records = namedtuple(\"Records\", (\"tournament_id\", \"t_start_date\", \"team_ind\", \"team_id\", \"players\", \"mask\",\n",
    "                                \"team_position\"))\n",
    "\n",
    "# получить словарь results с нужными результатами\n",
    "def get_results_dictionary():\n",
    "    \"\"\"получить нужные записи из results\"\"\"\n",
    "    with open(\"results.pkl\", 'rb') as f:\n",
    "        results_raw = pickle.load(f)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for key, lst in results_raw.items():\n",
    "        for lst_el in lst:\n",
    "            if 'mask' in lst_el and lst_el['mask'] is not None \\\n",
    "                    and 'teamMembers' in lst_el and lst_el['teamMembers']:\n",
    "                results[key] = lst\n",
    "    return results\n",
    "            \n",
    "def get_tournaments_start_dates():\n",
    "    \"\"\"получить даты начала турниров из tournaments\"\"\"\n",
    "    with open(\"tournaments.pkl\", 'rb') as f:\n",
    "        tournaments_data = pickle.load(f)\n",
    "\n",
    "    tournaments_data = {key: value for key, value in tournaments_data.items() } # if key in tournaments}\n",
    "\n",
    "    tournaments_start_dates = {key: value['dateStart'] for key, value in tournaments_data.items()}\n",
    "\n",
    "    del tournaments_data\n",
    "    return tournaments_start_dates\n",
    "\n",
    "tournaments_results = get_results_dictionary()\n",
    "tournaments_start_dates = get_tournaments_start_dates()\n",
    "\n",
    "\n",
    "# разделить турниры из results на train и test\n",
    "plays_train = []\n",
    "plays_test = []\n",
    "for tournament_id, lst in tournaments_results.items():\n",
    "    if lst is not None:\n",
    "        for team_ind, lst_el in enumerate(lst):\n",
    "            if lst_el['teamMembers'] is not None and lst_el['mask'] is not None:\n",
    "                \n",
    "                team_members = lst_el['teamMembers']\n",
    "                players = [i['player']['id'] for i in team_members]\n",
    "                team_id = lst_el['team']['id']\n",
    "                team_position = lst_el['team']['position'] if 'position' in lst_el['team'] else None\n",
    "                mask = lst_el['mask']\n",
    "                start_date = tournaments_start_dates[tournament_id]\n",
    "                \n",
    "                if pd.to_datetime(start_date).year == 2019:\n",
    "                            # and any([i in players_sample_set for i in players]):\n",
    "                    plays_train.append(Records(tournament_id=tournament_id, \n",
    "                                         t_start_date=start_date,\n",
    "                                         team_ind=team_ind, \n",
    "                                         team_id=team_id, \n",
    "                                         players=players, \n",
    "                                         mask=mask,\n",
    "                                         team_position=team_position\n",
    "                                        )\n",
    "                                )\n",
    "                elif pd.to_datetime(start_date).year == 2020:\n",
    "                    plays_test.append(Records(tournament_id=tournament_id, \n",
    "                                         t_start_date=start_date,\n",
    "                                         team_ind=team_ind, \n",
    "                                         team_id=team_id, \n",
    "                                         players=players, \n",
    "                                         mask=mask,\n",
    "                                         team_position=team_position\n",
    "                                        )\n",
    "                                )     \n",
    "with open(\"plays_train.pkl\", 'wb') as f:\n",
    "    pickle.dump(plays_train, f)\n",
    "    \n",
    "with open(\"plays_test.pkl\", 'wb') as f:\n",
    "    pickle.dump(plays_test, f)\n",
    "    \n",
    "del tournaments_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построить baseline-модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предсказания результатов ответов на вопросы каждого игрока мы будем использовать исторические данные по его результатам.\n",
    "\n",
    "__Основные предпосылки:__\n",
    "\n",
    "- Игрок, в среднем, участвует в турнирах той же сложности в которых он участвовал ранее. Переходы в турниры более высокого уровня сложности происходят постепенно (если происходят)\n",
    "- Игрок, в среднем, играет в команде того же уровня, что и ранее.\n",
    "- Модель учитывает данные по всем предыдущим играм.\n",
    "- X - данные по предыдущим турнирам и их результатам. y - ответы на вопросы в текущей игре. Для каждого значения ответа на вопрос в текущей игре (значение y) на вход модели на этапе обучения будет подаваться одна и та же строка, отражающая результаты предыдущих турниров для данного игрока.\n",
    "- Для обучающей выборки выбираем один момент времени для каждого игрока, чтобы данные для обучения были максимально независимы. Если данных недостаточно, то можно выбрать и более одного момента для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбрать моменты для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:09:24.196297Z",
     "start_time": "2021-05-11T15:08:45.696271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 86499/86499 [00:01<00:00, 57376.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 22395/22395 [00:00<00:00, 63017.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New df.dtypes: \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "player                    int32\n",
      "tournament_id             int32\n",
      "t_start_date     datetime64[ns]\n",
      "team_id                   int32\n",
      "mask                     object\n",
      "q_answered                int64\n",
      "q_total                   int64\n",
      "target                  float64\n",
      "dtype: object\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Число уникальных tournament_id (675, 2)\n",
      "New df.dtypes: \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "player                    int32\n",
      "tournament_id             int32\n",
      "t_start_date     datetime64[ns]\n",
      "team_id                   int32\n",
      "mask                     object\n",
      "q_answered                int64\n",
      "q_total                   int64\n",
      "target                  float64\n",
      "dtype: object\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Число уникальных tournament_id (173, 2)\n",
      "Wall time: 38.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"plays_train.pkl\", 'rb') as f:\n",
    "    plays_train = pickle.load(f)\n",
    "    \n",
    "with open(\"plays_test.pkl\", 'rb') as f:\n",
    "    plays_test = pickle.load(f)\n",
    "\n",
    "def get_df_by_player_for_plays(plays):\n",
    "    \"\"\"взять каждую запись со списком игроков и развернуть её в DataFrame,\n",
    "       где каждая строка отражает игрока\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=['player', 'tournament_id', 't_start_date', 'team_id', 'mask'])\n",
    "    to_concat = []\n",
    "    for record in tqdm(plays):\n",
    "        for player in record.players:\n",
    "            to_append = np.array(\n",
    "                [\n",
    "                [player, \n",
    "                 record.tournament_id, \n",
    "                 record.t_start_date, \n",
    "                 record.team_id, \n",
    "                 record.mask]\n",
    "                ]\n",
    "            )\n",
    "            to_concat.append(to_append)\n",
    "\n",
    "    to_concat = np.vstack(to_concat)\n",
    "\n",
    "    df = pd.DataFrame(to_concat, columns=['player', 'tournament_id', 't_start_date', 'team_id', 'mask'])\n",
    "\n",
    "    df = df.sort_values(by='player')\n",
    "    return df\n",
    "\n",
    "train_df = get_df_by_player_for_plays(plays_train)\n",
    "test_df = get_df_by_player_for_plays(plays_test)\n",
    "\n",
    "def add_target_features(df):\n",
    "    \"\"\"\n",
    "    первый шаг предобработки данных\n",
    "    1) поправить типы \n",
    "    2) добавить поле target на основе поля mask\n",
    "    3) отсортировать турниры игрока в хронологическом порядке\n",
    "    \n",
    "    Input:\n",
    "        df[['player', 'tournament_id', 't_start_date', 'team_id']]\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.astype({'player': int,\n",
    "                                'tournament_id': int,\n",
    "                                't_start_date': 'datetime64[ns]',\n",
    "                                'team_id': int,\n",
    "                                })\n",
    "\n",
    "    df.loc[:, 'q_answered'] = df['mask'].apply(lambda x: sum([int(i) for i in x if re.match(\"\\d\", i)]))\n",
    "    df.loc[:, 'q_total'] = df['mask'].str.len()\n",
    "\n",
    "    df.loc[:, 'target'] = df.q_answered / df.q_total\n",
    "\n",
    "    print(\"New df.dtypes: \\n\", \"-\" * 120, \"\\n\", df.dtypes, \"\\n\" ,\"-\" * 120, sep='')\n",
    "\n",
    "    df = df.sort_values(by=['player', 't_start_date'])\n",
    "\n",
    "    print(\"Число уникальных tournament_id\", \n",
    "          df[['tournament_id', 't_start_date']].drop_duplicates().shape\n",
    "         )\n",
    "    return df\n",
    "\n",
    "train_df = add_target_features(train_df)\n",
    "test_df = add_target_features(test_df)\n",
    "\n",
    "train_df.to_csv(\"train_df.csv\", index=False)\n",
    "test_df.to_csv(\"test_df.csv\", index=False)\n",
    "\n",
    "del train_df\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посчитать статистики для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:09:24.216196Z",
     "start_time": "2021-05-11T15:09:24.197297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_target_events_to_train(df):\n",
    "    df = df.sort_values(by=['player', 't_start_date'])\n",
    "    # игроки с более чем 3мя турнирами\n",
    "    df.loc[:, 'tournament_number'] = df.groupby(\"player\").tournament_id.cumcount() + 1\n",
    "    \n",
    "    players_with_tours = \\\n",
    "        df.groupby('player').tournament_number.max().loc[df.groupby('player').tournament_number.max() > 3].\\\n",
    "        index.tolist()\n",
    "\n",
    "    # случайно выбрать моменты для обучения по каждому игроку\n",
    "    moments_to_predict = \\\n",
    "        df.loc[df.player.isin(players_with_tours)].\\\n",
    "        groupby('player').tournament_number.max().apply(\n",
    "            lambda x: np.random.randint(4, x + 1)).reset_index()\n",
    "\n",
    "    # check uniqness\n",
    "    assert moments_to_predict.shape == moments_to_predict.drop_duplicates().shape\n",
    "\n",
    "    # проставить target_events\n",
    "    moments_to_predict.loc[:, 'target_event'] = 1\n",
    "    moments_to_predict.target_event = moments_to_predict.target_event.fillna(0)\n",
    "\n",
    "    # присоединить метку target_events к основному датасету\n",
    "    df = pd.merge(df, \n",
    "                  moments_to_predict,\n",
    "                  how='left',\n",
    "                  left_on=['player', 'tournament_number'],\n",
    "                  right_on=['player', 'tournament_number']\n",
    "                        )\n",
    "    print(\"Колонки: \", df.columns.tolist())\n",
    "    df.loc[:, 'target_event'] = df.target_event.fillna(0)\n",
    "    \n",
    "    df = df.drop(columns=['tournament_number'])\n",
    "    df = df.astype({\"target_event\": int})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_basic_features_on_history(df):\n",
    "    \"\"\"\n",
    "    расчёт базовых фичей по историческим данным турниров:\n",
    "    ['tours_num', \n",
    "     'avg_pct_answered',\n",
    "     'min_pct_answered',\n",
    "     'max_pct_answered',\n",
    "     'pct_answered_q_10',\n",
    "     'pct_answered_q_50',\n",
    "     'pct_answered_q_90',\n",
    "    ]\n",
    "    \"\"\"\n",
    "    WINDOW_UPPER_BOUND = 100\n",
    "    \n",
    "    df.loc[:, 'tours_num'] = df.groupby('player').tournament_id.cumcount()\n",
    "\n",
    "    # среднее\n",
    "    df.loc[:, \"avg_pct_answered\"] = \\\n",
    "        (df.groupby(\"player\").q_answered.cumsum() - df.q_answered) / \\\n",
    "        (df.groupby(\"player\").q_total.cumsum() - df.q_total)\n",
    "\n",
    "    # минимум\n",
    "    df.loc[:, 'min_pct_answered'] = df.groupby('player').target.rolling(WINDOW_UPPER_BOUND,\n",
    "                                                                        min_periods=1).min().values\n",
    "    df.loc[:, 'min_pct_answered'] = df.groupby(\n",
    "        \"player\")['min_pct_answered'].shift(1)\n",
    "\n",
    "    # максимум\n",
    "    df.loc[:, 'max_pct_answered'] = df.groupby('player').target.rolling(WINDOW_UPPER_BOUND,\n",
    "                                                                        min_periods=1).max().values\n",
    "    df.loc[:, 'max_pct_answered'] = df.groupby(\n",
    "        \"player\")['max_pct_answered'].shift(1)\n",
    "\n",
    "    # квантили\n",
    "    df.loc[:, 'pct_answered_q_10'] = df.groupby('player').target.rolling(WINDOW_UPPER_BOUND,\n",
    "                                                                         min_periods=1).quantile(0.1).values\n",
    "    df.loc[:, 'pct_answered_q_10'] = df.groupby(\n",
    "        \"player\")['pct_answered_q_10'].shift(1)\n",
    "\n",
    "    df.loc[:, 'pct_answered_q_90'] = df.groupby('player').target.rolling(WINDOW_UPPER_BOUND,\n",
    "                                                                         min_periods=1).quantile(0.9).values\n",
    "    df.loc[:, 'pct_answered_q_90'] = df.groupby(\n",
    "        \"player\")['pct_answered_q_90'].shift(1)\n",
    "\n",
    "    df.loc[:, 'pct_answered_q_50'] = df.groupby('player').target.rolling(WINDOW_UPPER_BOUND,\n",
    "                                                                         min_periods=1).quantile(0.5).values\n",
    "    df.loc[:, 'pct_answered_q_50'] = df.groupby(\n",
    "        \"player\")['pct_answered_q_50'].shift(1)\n",
    "    return df\n",
    "\n",
    "def add_basic_features_on_history_for_test(train_df, test_df):\n",
    "    \"\"\"\n",
    "        для тестовой выборки используем историю по 2019 году (то есть по train выборке)\n",
    "    \"\"\"\n",
    "    train_df.loc[:, 'is_train_record'] = 1\n",
    "    test_df.loc[:, 'is_train_record'] = 0\n",
    "\n",
    "    test_df_to_score = pd.concat([train_df[test_df.columns], test_df], axis=0)\n",
    "    \n",
    "    test_df_to_score = test_df_to_score.sort_values(by=['player', 't_start_date'])\n",
    "    test_df_to_score = add_basic_features_on_history(test_df_to_score)\n",
    "    \n",
    "    test_df = test_df_to_score.loc[test_df_to_score.is_train_record == 0]\n",
    "    test_df = test_df.sort_values(by=['player', 't_start_date'])\n",
    "    \n",
    "    train_df = train_df.drop(columns=['is_train_record'])\n",
    "    test_df = test_df.drop(columns=['is_train_record'])\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# посчитать X_train и y_train\n",
    "\n",
    "def get_X_y_train(train_df):\n",
    "    \"\"\" получить X_train и y_train для обучения на игроках, \n",
    "        а также meaning_col для идентификации игрока, турнира и вопроса\n",
    "    \"\"\"\n",
    "    \n",
    "    train_df = train_df.set_index(['player', 'tournament_id'])\n",
    "    train_df = train_df.loc[train_df.target_event == 1]\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = np.array([])\n",
    "    \n",
    "    mask_lengths = [len([j for j in i[-1] if re.match(\"\\d\", j)]) for i in train_df[['mask']].values]\n",
    "    \n",
    "    X_y_train = \\\n",
    "    np.vstack(\n",
    "    [np.hstack([\n",
    "        np.tile(i[:-1], (mask_lengths[item_number], 1)),\n",
    "        np.array([int(j) for j in i[-1] if re.match(\"\\d\", j)]).reshape(-1, 1)\n",
    "    ]\n",
    "    )\n",
    "        for item_number, i in enumerate(train_df[[\n",
    "                                 'tours_num',\n",
    "                                 'avg_pct_answered',\n",
    "                                 'min_pct_answered',\n",
    "                                 'max_pct_answered',\n",
    "                                 'pct_answered_q_10',\n",
    "                                 'pct_answered_q_90',\n",
    "                                 'pct_answered_q_50',\n",
    "                                 'mask']].values)])\n",
    "    \n",
    "    # сохранить индесы для X_train и y_train\n",
    "    X_y_meaning = \\\n",
    "    np.vstack(\n",
    "        [np.tile(ind, (mask_lengths[ind_number], 1))\n",
    "        for ind_number, ind in enumerate(train_df.index)]\n",
    "    )\n",
    "    X_y_meaning = pd.DataFrame(X_y_meaning, columns=['player', 'tournament'])\n",
    "    X_y_meaning.loc[:, 'question_number'] = X_y_meaning.groupby(['player', 'tournament']).tournament.cumcount() + 1\n",
    "    \n",
    "    return X_y_train[:, : -1], X_y_train[:, -1], X_y_meaning\n",
    "\n",
    "# аналогично на тесте\n",
    "def get_X_y_test(test_df):\n",
    "    \"\"\" получить X_test и y_test для обучения на игроках\"\"\"\n",
    "    test_df = test_df.set_index(['player', 'tournament_id'])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    X_test = test_df[['tours_num',\n",
    "                      'avg_pct_answered',\n",
    "                      'min_pct_answered',\n",
    "                      'max_pct_answered',\n",
    "                      'pct_answered_q_10',\n",
    "                      'pct_answered_q_90',\n",
    "                      'pct_answered_q_50',\n",
    "                      'mask']]\n",
    "    \n",
    "    y_test_prob = \\\n",
    "            test_df['mask'].apply(lambda x: sum([int(i) for i in x if re.match(\"\\d\", i)])) / \\\n",
    "            test_df['mask'].apply(lambda x: sum([1 for i in x if re.match(\"\\d\", i)]))\n",
    "\n",
    "    return X_test, y_test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:03.204151Z",
     "start_time": "2021-05-11T15:09:24.217142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонки:  ['player', 'tournament_id', 't_start_date', 'team_id', 'mask', 'q_answered', 'q_total', 'target', 'tournament_number', 'target_event']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "\n",
    "#############################  проставить target_events ###########################################################\n",
    "\n",
    "train_df = add_target_events_to_train(train_df) # на train обучаемся только на одном событии по каждому игроку\n",
    "test_df.loc[:, 'target_event'] = 1 # для теста делаем предсказания на всех событиях\n",
    "\n",
    "# колонки train и test одинаковые\n",
    "assert (train_df.columns == test_df.columns).all()\n",
    "\n",
    "#############################  добавить признаки для обучения #####################################################\n",
    "\n",
    "train_df = add_basic_features_on_history(train_df)\n",
    "train_df, test_df  = add_basic_features_on_history_for_test(train_df, test_df)\n",
    "\n",
    "assert (train_df.columns == test_df.columns).all()\n",
    "\n",
    "assert \\\n",
    "    train_df.loc[train_df.target_event == 1][['player', 'tournament_id']].shape == \\\n",
    "    train_df.loc[train_df.target_event == 1][[\n",
    "        'player', 'tournament_id']].drop_duplicates().shape\n",
    "\n",
    "#############################  посчитать выборки для обучения и сохранить #########################################\n",
    "\n",
    "X_train, y_train, X_y_meaning = get_X_y_train(train_df)\n",
    "\n",
    "with open(\"train_X_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump([X_train, y_train, X_y_meaning], f)\n",
    "\n",
    "\n",
    "#############################  посчитать выборки для проверки и сохранить #########################################\n",
    "\n",
    "X_test, y_test_prob = get_X_y_test(test_df)\n",
    "\n",
    "X_test = X_test.iloc[:, :-1]\n",
    "\n",
    "with open(\"test_X_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump([X_test, y_test_prob], f)\n",
    "\n",
    "############################  сохранить train_df и test_df с посчитанными статистиками #############################\n",
    "\n",
    "train_df.to_csv(\"train_df.csv\", index=False)\n",
    "test_df.to_csv(\"test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:03.850256Z",
     "start_time": "2021-05-11T15:14:03.205146Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"train_X_y.pkl\", \"rb\") as f:\n",
    "    X_train, y_train, X_y_meaning = pickle.load(f)\n",
    "\n",
    "with open(\"test_X_y.pkl\", \"rb\") as f:\n",
    "    X_test, y_test_prob = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:11.639940Z",
     "start_time": "2021-05-11T15:14:03.851278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "model.fit(X_train.astype(np.float32), y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:11.650912Z",
     "start_time": "2021-05-11T15:14:11.644928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041434, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:11.672895Z",
     "start_time": "2021-05-11T15:14:11.652906Z"
    }
   },
   "outputs": [],
   "source": [
    "y_prob_predicted = model.predict_proba(X_test.fillna(0))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:11.681900Z",
     "start_time": "2021-05-11T15:14:11.673888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player  tournament_id\n",
       "15      5730             0.500000\n",
       "        6181             0.194444\n",
       "        5753             0.777778\n",
       "        5968             0.514286\n",
       "        6265             0.395062\n",
       "                           ...   \n",
       "224693  5713             0.750000\n",
       "224694  5713             0.750000\n",
       "224695  5713             0.472222\n",
       "224696  5713             0.194444\n",
       "224697  5713             0.194444\n",
       "Name: mask, Length: 112841, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:11.689846Z",
     "start_time": "2021-05-11T15:14:11.683862Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"baseline_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверить качество модели на турнирах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:11.959630Z",
     "start_time": "2021-05-11T15:14:11.691841Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "\n",
    "with open(\"baseline_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:12.173234Z",
     "start_time": "2021-05-11T15:14:11.961570Z"
    }
   },
   "outputs": [],
   "source": [
    "# возьмём предсказанный и актуальный процент ответов и проверим корреляцию Спирмена и Кендалла\n",
    "\n",
    "test_predicted_vs_actual_df = \\\n",
    "pd.concat([y_test_prob.rename(\"Actual\"), \n",
    "           pd.Series(y_prob_predicted, index=y_test_prob.index, name='Predicted') \n",
    "          ], \n",
    "          axis=1)\n",
    "\n",
    "assert \\\n",
    "test_df[['player', 'tournament_id', 'team_id']].shape == \\\n",
    "test_df[['player', 'tournament_id', 'team_id']].drop_duplicates().shape\n",
    "\n",
    "# посчитать рейтинг команды в каждом турнире\n",
    "predicted_team_rating = \\\n",
    "pd.merge(test_predicted_vs_actual_df, \n",
    "         test_df[['player', 'tournament_id', 'team_id']],\n",
    "         how='left',\n",
    "         left_index=True,\n",
    "         right_on=['player', 'tournament_id']\n",
    "        ).groupby(['team_id', 'tournament_id']).Predicted.mean().reset_index()\n",
    "\n",
    "predicted_team_rating = predicted_team_rating.sort_values(by=['tournament_id', 'Predicted'],\n",
    "                                             ascending=[True, False])\n",
    "\n",
    "\n",
    "predicted_team_rating.loc[:, 'predicted_place_in_tourmanent'] = \\\n",
    "predicted_team_rating.groupby('tournament_id').cumcount(\"team_id\") + 1\n",
    "\n",
    "# актуальные результаты должны быть равны для всех игроков в команде, проверим это\n",
    "to_check = \\\n",
    "pd.merge(test_predicted_vs_actual_df, \n",
    "         test_df[['player', 'tournament_id', 'team_id']],\n",
    "         how='left',\n",
    "         left_index=True,\n",
    "         right_on=['player', 'tournament_id']\n",
    "        ).groupby(['team_id', 'tournament_id']).Actual.agg(['min', 'max', 'mean'])\n",
    "\n",
    "assert (to_check['min'] == to_check['max']).all()\n",
    "del to_check\n",
    "\n",
    "\n",
    "actual_test_positions = \\\n",
    "pd.merge(test_predicted_vs_actual_df, \n",
    "         test_df[['player', 'tournament_id', 'team_id']],\n",
    "         how='left',\n",
    "         left_index=True,\n",
    "         right_on=['player', 'tournament_id']\n",
    "        ).groupby(['team_id', 'tournament_id']).Actual.mean().reset_index()\n",
    "\n",
    "\n",
    "to_compare = \\\n",
    "pd.merge(\n",
    "    predicted_team_rating,\n",
    "    actual_test_positions,\n",
    "    how='left',\n",
    "    left_on = ['team_id', 'tournament_id'],\n",
    "    right_on = ['team_id', 'tournament_id']\n",
    ")\n",
    "\n",
    "to_compare = to_compare.sort_values(by=['tournament_id', 'Actual'], ascending=[True, False])\n",
    "\n",
    "to_compare.loc[:, \"actual_place_in_tourmanent\"] = to_compare.groupby(\"tournament_id\").team_id.cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:14:12.211989Z",
     "start_time": "2021-05-11T15:14:12.174069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Спирмен: SpearmanrResult(correlation=0.9110661032793113, pvalue=0.0)\n",
      "Кендалл: KendalltauResult(correlation=0.7592024799615623, pvalue=0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"Спирмен: \",\n",
    "spearmanr(to_compare['predicted_place_in_tourmanent'], \n",
    "          to_compare['actual_place_in_tourmanent']), \"\\n\",\n",
    "\"Кендалл: \",\n",
    "kendalltau(to_compare['predicted_place_in_tourmanent'], \n",
    "          to_compare['actual_place_in_tourmanent']), \"\\n\"\n",
    ", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель/расчёт для сложности вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:20.898675Z",
     "start_time": "2021-05-11T15:19:19.113219Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "\n",
    "with open(\"train_X_y.pkl\", \"rb\") as f:\n",
    "    X_train, y_train, train_X_y_meaning = pickle.load(f)\n",
    "\n",
    "with open(\"test_X_y.pkl\", \"rb\") as f:\n",
    "    X_test, y_test_prob = pickle.load(f)\n",
    "    \n",
    "with open(\"baseline_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:22.356080Z",
     "start_time": "2021-05-11T15:19:22.338082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>tournament_id</th>\n",
       "      <th>t_start_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>mask</th>\n",
       "      <th>q_answered</th>\n",
       "      <th>q_total</th>\n",
       "      <th>target</th>\n",
       "      <th>target_event</th>\n",
       "      <th>tours_num</th>\n",
       "      <th>avg_pct_answered</th>\n",
       "      <th>min_pct_answered</th>\n",
       "      <th>max_pct_answered</th>\n",
       "      <th>pct_answered_q_10</th>\n",
       "      <th>pct_answered_q_90</th>\n",
       "      <th>pct_answered_q_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>4973</td>\n",
       "      <td>2019-01-25 16:05:00</td>\n",
       "      <td>51584</td>\n",
       "      <td>111000101000101010001101110001000111</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5393</td>\n",
       "      <td>2019-01-25 17:00:00</td>\n",
       "      <td>48051</td>\n",
       "      <td>100010000011110111101001101010110011</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>5128</td>\n",
       "      <td>2019-02-08 16:00:00</td>\n",
       "      <td>51584</td>\n",
       "      <td>111111001101001001011010101000111111</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5429</td>\n",
       "      <td>2019-02-08 20:00:00</td>\n",
       "      <td>51584</td>\n",
       "      <td>00X110101110000011100001000010001001</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.594444</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5606</td>\n",
       "      <td>2019-04-11 21:00:00</td>\n",
       "      <td>51584</td>\n",
       "      <td>011010010101010100000000010000011000</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player  tournament_id         t_start_date  team_id  \\\n",
       "0      15           4973  2019-01-25 16:05:00    51584   \n",
       "1      15           5393  2019-01-25 17:00:00    48051   \n",
       "2      15           5128  2019-02-08 16:00:00    51584   \n",
       "3      15           5429  2019-02-08 20:00:00    51584   \n",
       "4      15           5606  2019-04-11 21:00:00    51584   \n",
       "\n",
       "                                   mask  q_answered  q_total    target  \\\n",
       "0  111000101000101010001101110001000111          17       36  0.472222   \n",
       "1  100010000011110111101001101010110011          19       36  0.527778   \n",
       "2  111111001101001001011010101000111111          22       36  0.611111   \n",
       "3  00X110101110000011100001000010001001          13       36  0.361111   \n",
       "4  011010010101010100000000010000011000          11       36  0.305556   \n",
       "\n",
       "   target_event  tours_num  avg_pct_answered  min_pct_answered  \\\n",
       "0             0          0               NaN               NaN   \n",
       "1             0          1          0.472222          0.472222   \n",
       "2             0          2          0.500000          0.472222   \n",
       "3             0          3          0.537037          0.472222   \n",
       "4             0          4          0.493056          0.361111   \n",
       "\n",
       "   max_pct_answered  pct_answered_q_10  pct_answered_q_90  pct_answered_q_50  \n",
       "0               NaN                NaN                NaN                NaN  \n",
       "1          0.472222           0.472222           0.472222           0.472222  \n",
       "2          0.527778           0.477778           0.522222           0.500000  \n",
       "3          0.611111           0.483333           0.594444           0.527778  \n",
       "4          0.611111           0.394444           0.586111           0.500000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:22.844086Z",
     "start_time": "2021-05-11T15:19:22.841093Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 6));\n",
    "# plt.hist(train_df.groupby(\"tournament_id\").team_id.nunique(), \n",
    "#          bins=100, histtype='step', cumulative=True, );\n",
    "# plt.xticks(np.arange(0, 2000, 50))\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:28.771204Z",
     "start_time": "2021-05-11T15:19:23.222839Z"
    }
   },
   "outputs": [],
   "source": [
    "# посчитать процент ответов\n",
    "tournaments_for_train = train_df.groupby(\"tournament_id\").team_id.nunique().\\\n",
    "loc[train_df.groupby(\"tournament_id\").team_id.nunique() > 10].index\n",
    "\n",
    "tournament_x_question = []\n",
    "for ind, group in train_df[['tournament_id', 'team_id', \"mask\"]].drop_duplicates().groupby(\"tournament_id\"):\n",
    "    function_to_apply = lambda x: np.array([int(i) for i in x.replace(\"?\", \"0\") if re.match(\"\\d\", i)])\n",
    "    \n",
    "    lists = group['mask'].apply(function_to_apply)\n",
    "    # привести длины в порядок\n",
    "    lists = list(zip(*lists))\n",
    "    pct_answered = np.vstack(lists).mean(axis=0)\n",
    "    \n",
    "    by_tournament = [(i[0], ind + 1, i[1])  for ind, i in enumerate(product([ind], pct_answered))]\n",
    "    tournament_x_question.append(by_tournament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:28.775996Z",
     "start_time": "2021-05-11T15:19:28.772007Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['tours_num',\n",
    "                             'avg_pct_answered',\n",
    "                             'min_pct_answered',\n",
    "                             'max_pct_answered',\n",
    "                             'pct_answered_q_10',\n",
    "                             'pct_answered_q_90',\n",
    "                             'pct_answered_q_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:29.177076Z",
     "start_time": "2021-05-11T15:19:28.777991Z"
    }
   },
   "outputs": [],
   "source": [
    "# посчитаем рейтинг команд\n",
    "predictions = model.predict_proba(train_df[features].fillna(0))[:, 1]\n",
    "\n",
    "\n",
    "for_team_rating = train_df[['team_id', \"tournament_id\", 'mask']].reset_index()\n",
    "\n",
    "for_team_rating.loc[:, 'predicted_rating'] = predictions\n",
    "\n",
    "team_rating = for_team_rating.groupby(['team_id', 'tournament_id', 'mask']).predicted_rating.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:29.180913Z",
     "start_time": "2021-05-11T15:19:29.177953Z"
    }
   },
   "outputs": [],
   "source": [
    "# визуальная проверка на одинаковое число вопросов\n",
    "# team_rating.assign(mask_length = team_rating['mask'].str.len()).groupby('tournament_id').mask_length.agg(['min','max','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:29.367827Z",
     "start_time": "2021-05-11T15:19:29.181956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# распределение команд по предсказанному рейтингу\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.hist(team_rating.predicted_rating, \n",
    "         bins=np.arange(0, 1.1, 0.05), \n",
    "         histtype='step',\n",
    "         cumulative=False,\n",
    "         density=True,\n",
    "         linewidth=2\n",
    "        );\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:49.607632Z",
     "start_time": "2021-05-11T15:19:29.368814Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 675/675 [00:20<00:00, 33.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_complexities = []\n",
    "for tournament_id, group in tqdm(team_rating.groupby('tournament_id')):\n",
    "    # print(group['mask'].str.len().min())\n",
    "    for q_number in range(1,  group['mask'].str.len().min() + 1):\n",
    "        q_complexity = group.loc[group['mask'].apply(lambda x: x[q_number - 1] == '1')].predicted_rating.mean()\n",
    "        q_complexities.append((tournament_id, q_number, q_complexity))\n",
    "\n",
    "q_complexities = pd.DataFrame(q_complexities, columns=['tournament_id', 'q_number', 'q_complexity'])\n",
    "\n",
    "q_complexities.to_csv(\"q_complexities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Способ ранжирования команд на основе рейтинга игроков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- рейтинг игрока по baseline-модели - оценка вероятности, что команда этого игрока правильно ответит на этот вопрос\n",
    "- возьмём числовые характеристики рейтингов игроков в команде (среднее, медиана, процентили) и обучим модель на этих рейтингах\n",
    "\n",
    "\n",
    "__предпосылки:__\n",
    "- рейтинг игроков якобы не содержит информации о целевой переменной (несмотря на, то, что предпосылка нарушается можно сказать, что рейтинг игроков содержит мало информации о результате конкретной игры и попробовать обучить веса логистической регрессии на характеристиках распределения (min, max, avg, квантили) рейтингов игроков в команде)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Возьмём модель для baseline и обучим вторую модель поверх её предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:51.464860Z",
     "start_time": "2021-05-11T15:19:49.608630Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "\n",
    "with open(\"train_X_y.pkl\", \"rb\") as f:\n",
    "    X_train, y_train, X_y_meaning = pickle.load(f)\n",
    "\n",
    "with open(\"test_X_y.pkl\", \"rb\") as f:\n",
    "    X_test, y_test_prob = pickle.load(f)\n",
    "    \n",
    "with open(\"baseline_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "features = ['tours_num',\n",
    "            'avg_pct_answered',\n",
    "            'min_pct_answered',\n",
    "            'max_pct_answered',\n",
    "            'pct_answered_q_10',\n",
    "            'pct_answered_q_90',\n",
    "            'pct_answered_q_50']\n",
    "\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = f\"percentile_{n}\"\n",
    "    return percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:19:51.469975Z",
     "start_time": "2021-05-11T15:19:51.466983Z"
    }
   },
   "outputs": [],
   "source": [
    "# q_complexities = pd.read_csv(\"q_complexities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:19.582628Z",
     "start_time": "2021-05-11T15:19:51.471970Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_features(df, model):\n",
    "    \"\"\"посчитать предсказания модели на игроках из df\"\"\"\n",
    "    prediction = model.predict_proba(df[features].fillna(0))[:, 1]\n",
    "    train_to_aggregate_personal_ratings = df[['player', 'tournament_id', 'team_id']].copy()\n",
    "    train_to_aggregate_personal_ratings.loc[:, 'player_rating'] = prediction\n",
    "\n",
    "    train_by_team = train_to_aggregate_personal_ratings[['player',\n",
    "                                                         'tournament_id',\n",
    "                                                         'team_id',\n",
    "                                                         'player_rating']].drop_duplicates()\\\n",
    "        .groupby([\"team_id\",\n",
    "                  \"tournament_id\"]).player_rating.agg([\n",
    "                      'min',\n",
    "                      'max',\n",
    "                      'mean',\n",
    "                      percentile(10),\n",
    "                      percentile(90)\n",
    "                  ]\n",
    "    )\n",
    "\n",
    "    train_by_team.columns = [\"agg_by_team_\" + i for i in train_by_team.columns]\n",
    "    return train_by_team\n",
    "\n",
    "def get_train_sample(train_by_team, train_df):\n",
    "    # развернём DataFrame вдоль маски\n",
    "    to_ravel = train_df[['team_id', 'tournament_id', 'mask']].drop_duplicates()\n",
    "    to_ravel_along = [np.array([int(j) for j in i if re.match(\"\\d\", j)], dtype=np.int) for i in to_ravel['mask']]\n",
    "\n",
    "    def ravel_df_values(df_to_ravel: pd.DataFrame, values_to_ravel_along: List[np.array]):\n",
    "        mask_lengths = [len(j) for j in values_to_ravel_along]\n",
    "\n",
    "        raveled_values = \\\n",
    "        np.hstack(\n",
    "            [\n",
    "                np.vstack(\n",
    "                    [np.tile(row[:-1], (mask_lengths[item_number] , 1))\n",
    "                        for item_number, row in enumerate(df_to_ravel.values)\n",
    "                    ]\n",
    "                ),\n",
    "                np.hstack(values_to_ravel_along).reshape(-1, 1)\n",
    "            ]   \n",
    "        )\n",
    "        return raveled_values\n",
    "\n",
    "    raveled_df = ravel_df_values(to_ravel, to_ravel_along)\n",
    "    raveled_df = pd.DataFrame(raveled_df, columns = ['team_id', 'tournament_id', 'target'])\n",
    "\n",
    "    train_by_team = \\\n",
    "    pd.merge(train_by_team, raveled_df.set_index(['team_id', 'tournament_id']),\n",
    "                                                how='inner',\n",
    "            left_index=True,\n",
    "            right_index=True)\n",
    "    return train_by_team\n",
    "\n",
    "# def add_prob_target(df, ):\n",
    "#     df.loc[:, 'prob_target'] = df.groupby(['team_id', 'tournament_id'])[['target']].mean()\n",
    "#     return df\n",
    "\n",
    "\n",
    "train_by_team = add_features(train_df, model)\n",
    "train_by_team = get_train_sample(train_by_team, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:23.876142Z",
     "start_time": "2021-05-11T15:20:19.584443Z"
    }
   },
   "outputs": [],
   "source": [
    "test_by_team = add_features(test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:23.896968Z",
     "start_time": "2021-05-11T15:20:23.877096Z"
    }
   },
   "outputs": [],
   "source": [
    "test_by_team.loc[:, 'prob_target'] = test_df.groupby(['team_id', 'tournament_id'])[['target']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.767064Z",
     "start_time": "2021-05-11T15:20:23.897922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(C=0.01, penalty='l2', solver='saga')\n",
    "model2.fit(\n",
    "    train_by_team.drop(columns=['target']).values,\n",
    "    train_by_team['target'].values.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.772086Z",
     "start_time": "2021-05-11T15:20:54.768061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-0.37902564  0.84009503  1.5535578   0.31547191  1.22577267]]\n",
      "Intercept: [-1.86828328]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients:\", model2.coef_)\n",
    "print(\"Intercept:\", model2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.781067Z",
     "start_time": "2021-05-11T15:20:54.773048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112841,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.790353Z",
     "start_time": "2021-05-11T15:20:54.782024Z"
    }
   },
   "outputs": [],
   "source": [
    "test_model_prediction = model2.predict_proba(test_by_team.drop(columns=['prob_target']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.952130Z",
     "start_time": "2021-05-11T15:20:54.793347Z"
    }
   },
   "outputs": [],
   "source": [
    "merged = \\\n",
    "pd.merge(\n",
    "pd.DataFrame(test_model_prediction.reshape(-1, 1), index=test_by_team.index, columns=['Prediction']),\n",
    "test_df.groupby(['tournament_id', 'team_id']).target.mean().to_frame().rename(columns={'target': 'Actual_result'}),\n",
    "    how='inner',\n",
    "    left_index=True,\n",
    "    right_index=True)\n",
    "\n",
    "merged = merged.reset_index().sort_values(by=['tournament_id', 'Actual_result'], ascending=[True, False])\n",
    "merged.loc[:, 'Actual_place_in_tournament'] = merged.groupby('tournament_id').team_id.cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.968122Z",
     "start_time": "2021-05-11T15:20:54.953129Z"
    }
   },
   "outputs": [],
   "source": [
    "merged = merged.sort_values(by=['tournament_id', 'Prediction'], ascending=[True, False])\n",
    "merged.loc[:, 'predicted_place_in_tournament'] = merged.groupby('tournament_id').team_id.cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:20:54.984104Z",
     "start_time": "2021-05-11T15:20:54.969120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Спирмен: SpearmanrResult(correlation=0.9035132291329181, pvalue=0.0)\n",
      "Кендалл: KendalltauResult(correlation=0.7468363455287789, pvalue=0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"Спирмен: \",\n",
    "spearmanr(merged['predicted_place_in_tournament'], \n",
    "          merged['Actual_place_in_tournament']), \"\\n\",\n",
    "\"Кендалл: \",\n",
    "kendalltau(merged['predicted_place_in_tournament'], \n",
    "          merged['Actual_place_in_tournament']), \"\\n\"\n",
    ", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание по EM-алгоритму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:21:57.656139Z",
     "start_time": "2021-05-11T15:20:54.985610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "START_MIN_QUESTION_NUMBER = 1000\n",
    "\n",
    "def get_tournaments_id_for_year(year, tournaments, results):\n",
    "    this_year_tournaments = [value for key, value in tournaments.items() if value['dateStart'][:4] == str(year)]\n",
    "    tournaments_needed = [i for i in this_year_tournaments \\\n",
    "                          if i['id'] in results and results[i['id']] != [] and 'mask' in results[i['id']][0]]\n",
    "    return [i['id'] for i in tournaments_needed]\n",
    "\n",
    "def create_table(tournament_ids, results):\n",
    "    for_table = []\n",
    "    global_question_id = 0\n",
    "    \n",
    "    for t_id, t_data in results.items():\n",
    "        if t_id in tournament_ids:\n",
    "            min_number_of_questions = START_MIN_QUESTION_NUMBER\n",
    "            for team in t_data:\n",
    "                if 'mask' in team and team['mask'] != None:\n",
    "                    if len(team['mask']) < min_number_of_questions:\n",
    "                        min_number_of_questions = len(team['mask'])\n",
    "            \n",
    "            for team in t_data:\n",
    "                if 'mask' in team and team['mask'] != None:\n",
    "                    q_answered = 0\n",
    "                    for answer in str(team['mask']):\n",
    "                        if answer in ['0', '1']:\n",
    "                            q_answered += int(answer)\n",
    "                    \n",
    "                    team_id = team['team']['id']\n",
    "                    for member in team['teamMembers']:\n",
    "                        member_id = member['player']['id']\n",
    "                        for question_num in range(min_number_of_questions):\n",
    "                            answer = team['mask'][question_num]\n",
    "                            if answer in ['0', '1']:\n",
    "                                for_table.append([t_id, \n",
    "                                                  team_id, \n",
    "                                                  member_id, \n",
    "                                                  question_num,\n",
    "                                                  int(answer),\n",
    "                                                  q_answered,\n",
    "                                                  global_question_id + question_num])\n",
    "                \n",
    "            # для каждого турнира добавить число использованных вопросов для global_question_id\n",
    "            global_question_id += min_number_of_questions\n",
    "                                \n",
    "    return pd.DataFrame(for_table, columns=['tournament_id', 'team_id', 'member_id', \n",
    "                                            'q_num', 'answer', 'q_answered',\n",
    "                                            'global_question_id'])\n",
    "\n",
    "with open(\"tournaments.pkl\", 'rb') as f:\n",
    "    tournaments = pickle.load(f)\n",
    "    \n",
    "with open(\"results.pkl\", 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "train_tournaments_ids =  get_tournaments_id_for_year(2019, tournaments, results)\n",
    "test_tournaments_ids =  get_tournaments_id_for_year(2020, tournaments, results)\n",
    "\n",
    "train_df = create_table(train_tournaments_ids, results)\n",
    "\n",
    "del results\n",
    "del tournaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:22:02.911843Z",
     "start_time": "2021-05-11T15:21:57.658096Z"
    }
   },
   "outputs": [],
   "source": [
    "# сделать X_train, y_train\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = one_hot_enc.fit_transform(train_df[['member_id', 'global_question_id']])\n",
    "y_train = np.array(train_df['answer'], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:22:02.918669Z",
     "start_time": "2021-05-11T15:22:02.913692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90909"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_enc.categories_[0]) + len(one_hot_enc.categories_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:22:06.319924Z",
     "start_time": "2021-05-11T15:22:02.921672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17913374, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# игрок X вопрос\n",
    "train_df[['member_id', 'global_question_id']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:22:06.335494Z",
     "start_time": "2021-05-11T15:22:06.321919Z"
    }
   },
   "outputs": [],
   "source": [
    "n_sample = 100_000\n",
    "toy_X = X_train[:n_sample].copy()\n",
    "toy_y = y_train[:n_sample].copy()\n",
    "toy_train_df = train_df.head(n_sample).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM - алгоритм (реализация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:22:06.341506Z",
     "start_time": "2021-05-11T15:22:06.336544Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def create_logger():\n",
    "    logger = logging.getLogger(\"my_logger\")\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.handlers = []\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:24:58.311602Z",
     "start_time": "2021-05-11T15:22:06.342504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 18:22:22,738 - INFO - 0 iterations done\n",
      "2021-05-11 18:22:39,962 - INFO - 1 iterations done\n",
      "2021-05-11 18:22:57,136 - INFO - 2 iterations done\n",
      "2021-05-11 18:23:14,502 - INFO - 3 iterations done\n",
      "2021-05-11 18:23:31,493 - INFO - 4 iterations done\n",
      "2021-05-11 18:23:48,695 - INFO - 5 iterations done\n",
      "2021-05-11 18:24:06,030 - INFO - 6 iterations done\n",
      "2021-05-11 18:24:23,580 - INFO - 7 iterations done\n",
      "2021-05-11 18:24:40,983 - INFO - 8 iterations done\n",
      "2021-05-11 18:24:58,307 - INFO - 9 iterations done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "class EM:\n",
    "    def __init__(self, learning_rate = 1, iterations = 10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def _get_question_probability(self, q_id):\n",
    "        row_num = q_id\n",
    "        result = expit(self.X[row_num] @ self.W + self.b)[0][0]\n",
    "        return result\n",
    "    \n",
    "    def _E_step(self, data):\n",
    "        self.team_results.loc[:, 'question_prob'] = self.team_results.apply(lambda x: \\\n",
    "                                                        self._get_question_probability(x['global_question_id']), \n",
    "                                                                       axis=1\n",
    "                                                                        )\n",
    "        # аггрегация по команде\n",
    "        self.team_results.loc[:, 'team_prob'] =  self.team_results.groupby(['team_id', \n",
    "                                                                          'global_question_id'])['question_prob'].\\\n",
    "            transform(lambda x: np.prod(1 - x))\n",
    "        self.team_results.loc[:, 'team_prob'] = self.team_results.groupby('team_prob').apply(lambda x: 1 - x)\n",
    "        \n",
    "        self.Z = (self.team_results['question_prob'] / self.team_results['team_prob']).to_numpy()\n",
    "        self.Z[self.Y == 0] = 0    \n",
    "        logger.debug(\"E-step done\")\n",
    "        \n",
    "    def _M_step(self):\n",
    "        A = expit(self.X.dot(self.W) + self.b) \n",
    "        tmp = (A - self.Z.T.reshape(A.shape)).reshape(-1, 1)\n",
    "        \n",
    "        dW = (self.X.T @ tmp) / self.n_records\n",
    "        db = np.sum(tmp) / self.n_records\n",
    "        \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        logger.debug(\"M-step done\")\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y, data):\n",
    "        self.n_records, self.n_features = X.shape\n",
    "        \n",
    "        self.W = np.zeros(self.n_features).reshape(-1, 1)\n",
    "        self.b = 0\n",
    "        self.X, self.Y, self.Z = X, Y, Y\n",
    "        \n",
    "        self.team_results = pd.DataFrame({'team_id': data['team_id'], \n",
    "                                          'global_question_id': data['global_question_id']\n",
    "                                         })\n",
    "        self.team_results['q_prob'] = self.Y\n",
    "        self.team_results['t_prob'] = self.Y\n",
    "        data['Z'] = self.Z\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            self._E_step(data)\n",
    "            self._M_step()\n",
    "            logger.info(f\"%s iterations done\", _)\n",
    "            \n",
    "    def predict(self, X) :    \n",
    "        temp = expit(X @ self.W + self.b)\n",
    "        y_pred = np.where(temp > 0.5, 1, 0 )           \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        return expit(X @ self.W + self.b)  \n",
    "        \n",
    "em = EM(iterations=10)\n",
    "\n",
    "em.fit(toy_X, toy_y, toy_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:24:58.319322Z",
     "start_time": "2021-05-11T15:24:58.312470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23766245],\n",
       "       [0.23670189],\n",
       "       [0.23399832],\n",
       "       ...,\n",
       "       [0.23367019],\n",
       "       [0.23167888],\n",
       "       [0.23641768]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.predict_prob(toy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "358px",
    "width": "626px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "521.4px",
    "left": "1169px",
    "right": "20px",
    "top": "120px",
    "width": "347px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
